{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24416a6c-36fa-4034-b8d6-d4d316a75344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "from kneed import KneeLocator\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd4cbef8-92c9-4ff8-9155-edd9ec16eb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_elbow_threshold(df_label_counts, y_name=\"count\", y_label=\"Number of samples\"):\n",
    "    x = df_label_counts.index\n",
    "    y = df_label_counts[y_name]\n",
    "    kn = KneeLocator(x=x, y=y, curve='convex', direction='increasing')\n",
    "    knee = kn.knee\n",
    "    return df_label_counts.iloc[knee][\"label\"], df_label_counts.iloc[knee][y_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "337e83f7-9148-4e4d-8390-37faa4135f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_clusters_with_few_samples(df, thresh=None, suffix=\"\"):\n",
    "    \"\"\" If thresh is None, the Kneedle algorithm will be used to determine a treshold. \"\"\"\n",
    "    temp = df.copy()\n",
    "    \n",
    "    # count number of grid cells in each cluster\n",
    "    df_nums = temp.groupby(\"label\").count()[\"e0\"].reset_index().rename(columns={\"e0\": \"count\"})\n",
    "    df_nums = df_nums.sort_values(\"count\").reset_index(drop=True)\n",
    "    df_nums[\"label\"] = df_nums[\"label\"].astype(str)\n",
    "\n",
    "    # compute threshold to cut off clusters\n",
    "    if not thresh:\n",
    "        cluster_label, thresh = compute_elbow_threshold(df_nums, y_name=\"count\", y_label=\"Log number of samples\")\n",
    "\n",
    "    # set all labels to -2 or -1 (noise) where num samples is too small\n",
    "    labels_to_keep = list(df_nums[df_nums[\"count\"] >= thresh].label)\n",
    "    # temp.loc[~(temp.label.astype(str).isin(labels_to_keep)), \"label\"] = -1\n",
    "\n",
    "    # drop small clusters\n",
    "    temp = temp[temp.label.astype(str).isin(labels_to_keep)]\n",
    "\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a25ecc-16e2-4bce-8221-2129cde06879",
   "metadata": {},
   "source": [
    "# Repeat UMAP-DBSCAN runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af3f487a-782e-49ac-9d14-c9b27a1d7859",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@dask.delayed\n",
    "def compute_labels(df):\n",
    "    # compute embedding\n",
    "    embedding = umap.UMAP(min_dist=0.0, n_components=3, n_neighbors=20).fit_transform(df_scaled)\n",
    "\n",
    "    # compute clustering\n",
    "    model = DBSCAN(eps=0.1, min_samples=3).fit(embedding)\n",
    "\n",
    "    # drop small clusters?\n",
    "    embedding = pd.DataFrame(embedding, columns=[\"e0\", \"e1\", \"e2\"])\n",
    "    embedding[\"label\"] = model.labels_\n",
    "    dropped = drop_clusters_with_few_samples(embedding, thresh=None)\n",
    "    \n",
    "    return dropped.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e5ee64b-631c-45f4-b29d-9a6cc1e1a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = Client(n_workers=4)\n",
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "094dd823-7693-43f5-a091-edec6209571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df_in = pd.read_csv(\"data/df_wide_knn.csv\") \n",
    "df = df_in.drop([\"LATITUDE\", \"LONGITUDE\", \"LEV_M\"], axis=1)  # remove geolocation\n",
    "\n",
    "# scale data\n",
    "scaler = MinMaxScaler().fit(df)\n",
    "df_scaled = pd.DataFrame(scaler.transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5351911b-c9f1-44e2-a752-aefde6c9bdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1c89b6-0c4f-4052-88a7-26c391461cfd",
   "metadata": {},
   "source": [
    "# Re-run the UMAP-DBSCAN several times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19e0431-d9bc-482d-89fb-13eb5c6b4d25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "labels_list = []\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    print(i)\n",
    "    labels_list.append(compute_labels(df_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aeeea6-b179-4794-8731-af7a3ee48e6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# res = dask.compute(*labels_list)\n",
    "res = labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02579a7c-8b43-4e6f-86c7-5c7ed7ecde38",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"res_withDrop.pickle\", \"wb\") as fp:   \n",
    "    pickle.dump(res, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230ced75-493d-4ef0-9c64-9695c3d8b618",
   "metadata": {},
   "source": [
    "# Cluster matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c07b6ef-fe61-434c-9194-380570824433",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"res_withDrop.pickle\", \"rb\") as fp:\n",
    "    res = pickle.load(fp)\n",
    "labels_list = res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ae75bb-0667-41ae-89a7-2a63b28d86ce",
   "metadata": {},
   "source": [
    "## Step 1: Find maximum overlapping labels/clusters for each combination of clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6898cc3-c120-4af1-9580-40546ef1df17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compare outputs matching by #overlapping samples\n",
    "num_iterations = len(res)\n",
    "res_matching = []\n",
    "for i in range(num_iterations):\n",
    "    for j in range(num_iterations):\n",
    "        if i != j:\n",
    "            print(i, j)\n",
    "\n",
    "            # load both label sets\n",
    "            a = pd.DataFrame(labels_list[i], columns=[\"label\"])  # pd.read_csv(output_dir + f\"eps_{eps}-min_samples_{min_samples}-iteration_{i}.csv\")\n",
    "            b = pd.DataFrame(labels_list[j], columns=[\"label\"])  # pd.read_csv(output_dir + f\"eps_{eps}-min_samples_{min_samples}-iteration_{j}.csv\")\n",
    "\n",
    "            # compute number of clusters of both clusterings\n",
    "            num_clusters_a = len(a['label'].unique())\n",
    "            num_clusters_b = len(b['label'].unique())\n",
    "            print(f\"Number of clusters difference: {num_clusters_a - num_clusters_b}\")\n",
    "\n",
    "            # compare num samples per cluster\n",
    "            num_samples_a = pd.DataFrame(a.value_counts()).reset_index()\n",
    "            num_samples_b = pd.DataFrame(b.value_counts()).reset_index()\n",
    "\n",
    "            # match clusters by computing sample overlap\n",
    "            df_labels = df_in.copy()\n",
    "            df_labels[\"label_a\"] = a\n",
    "            df_labels[\"label_b\"] = b\n",
    "\n",
    "            # iterate over each cluster in a\n",
    "            for c in np.sort(a[\"label\"].unique()):\n",
    "                # check potential matches (given label c (from clusterin a), which labels in clustering b are at the same points?\n",
    "                matches = pd.DataFrame(df_labels[df_labels[\"label_a\"] == c][\"label_b\"])\n",
    "                match_counts = matches.value_counts().reset_index()\n",
    "                num_matches = len(match_counts)\n",
    "\n",
    "                # what is the cluster in b, that has most points in common with cluster c (from clustering a)?\n",
    "                max_match = match_counts[match_counts[\"count\"] == match_counts[\"count\"].max()]\n",
    "\n",
    "                # if all samples in c got assigned the same cluster in b, num_matches will be 1\n",
    "                if num_matches != 0:\n",
    "                    res_matching.append({\"clustering_a\": i, \"clustering_b\": j,\n",
    "                                \"label_a\": c,\n",
    "                                \"label_b\": max_match[\"label_b\"].values[0],\n",
    "                                \"num_samples_a\": len(matches),\n",
    "                                \"num_samples_max_match\": max_match[\"count\"].values[0],\n",
    "                                \"difference\": len(matches) - max_match[\"count\"].values[0]})\n",
    "                else:\n",
    "                    # if no matching cluster was found\n",
    "                    res_matching.append({\"clustering_a\": i, \"clustering_b\": j,\n",
    "                                \"label_a\": c,\n",
    "                                \"label_b\": np.nan,\n",
    "                                \"num_samples_a\": len(matches),\n",
    "                                \"num_samples_max_match\": np.nan,\n",
    "                                \"difference\": np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaa1896-598a-4b90-a97f-c69918ad2838",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap = pd.DataFrame(res_matching)\n",
    "df_overlap.to_csv(\"overlap_withDrop.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5992a9-daee-4c6f-96ef-c651f3d6e6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e03cb7-c2f7-40cb-a571-9fc63aa67953",
   "metadata": {},
   "source": [
    "## Step 2: Apply the label mapping and count the number of different labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f6f9ae-8493-4665-aa8e-90642303b9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap = pd.read_csv(\"overlap.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ed2ffb-0936-418b-8e57-5a53512c09d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainties = []\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    for j in range(num_iterations):\n",
    "        if i != j: \n",
    "            temp = df_in.copy()\n",
    "            \n",
    "            # define mapping between clustering a and b\n",
    "            mapping = df_overlap[(df_overlap.clustering_a == i) & (df_overlap.clustering_b == j)][[\"label_a\", \"label_b\"]]\n",
    "            mapping_dict = {x[1].label_b: x[1].label_a for x in mapping.iterrows()}\n",
    "            \n",
    "            # add labels to initial df\n",
    "            temp[\"label_a\"] = res[i]\n",
    "            temp[\"label_b\"] = res[j]\n",
    "            temp[\"label_b_mapped\"] = temp[\"label_b\"].map(mapping_dict)  # this is the label mapping\n",
    "            \n",
    "            # uncertainty as number of different labels\n",
    "            uncertainties.append(temp.label_a != temp.label_b_mapped)  # if labels are unequal, this will be 1 (or True), i.e. we count how many different labels each datapoint has over the iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cc1dd7-6ff2-47d5-a6ab-199d704591e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize uncertainties (ignore the diagonal)\n",
    "df_in[\"uncertainty\"] = np.array(uncertainties).sum(axis=0)/(num_iterations*num_iterations-num_iterations)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abee441-a28f-4022-bb7c-ac33d89787fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in.to_csv(\"uncertainty.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f229a5-248e-4474-8ec6-c3e90767ad1b",
   "metadata": {},
   "source": [
    "# Plot uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333017e9-70b6-4bae-8763-9df425af75c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in = pd.read_csv(\"uncertainty.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cecde8-222f-4736-9aba-b18d7af518d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute embedding\n",
    "embedding = umap.UMAP(min_dist=0.0, n_components=3, n_neighbors=20).fit_transform(df_scaled)\n",
    "\n",
    "# visualize embedding\n",
    "fig = plt.figure(figsize=(7, 6))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(embedding[:, 0], embedding[:, 1], embedding[:, 2], alpha=0.08, s=2, marker=\".\")\n",
    "plt.xlabel(\"Axis 0\")\n",
    "plt.ylabel(\"Axis 1\")\n",
    "ax.set_zlabel(\"Axis 2\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"output/umap_space.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ee8895-9cf4-4c0a-8eba-22d655107a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in[\"e0\"] = embedding[:, 0]\n",
    "df_in[\"e1\"] = embedding[:, 1]\n",
    "df_in[\"e2\"] = embedding[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e826008-0149-4242-a17b-eab5d57067fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_in[\"uncertainty\"]) # many uncertain points...\n",
    "plt.xlabel(\"Uncertainty [%]\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output_old/dbscan/uncertainty/uncertainty_withDrop_histplot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073effa5-66b1-495c-8c52-e26f8688a31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df_in[\"uncertainty\"]) # many uncertain points...\n",
    "plt.ylabel(\"Uncertainty [%]\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output_old/dbscan/uncertainty/uncertainty_withDrop_boxplot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30ae1f8-e4ef-4db3-a4b1-703f30c20bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Basemap\n",
    "mymap = Basemap(llcrnrlon=temp[\"LONGITUDE\"].min(), llcrnrlat=temp[\"LATITUDE\"].min(), \n",
    "                urcrnrlon=temp[\"LONGITUDE\"].max(), urcrnrlat=temp[\"LATITUDE\"].max(), fix_aspect=False)\n",
    "\n",
    "# plot\n",
    "figsize = (6, 6)\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "sc_3d = ax.scatter(df_in[\"LONGITUDE\"], df_in[\"LATITUDE\"], df_in[\"LEV_M\"], c=df_in[\"uncertainty\"], s=0.5, alpha=1, zorder=4)  # df[\"predictions\"]\n",
    "ax.add_collection3d(mymap.drawcoastlines(linewidth=0.5))\n",
    "ax.set_box_aspect((np.ptp(df_in[\"LONGITUDE\"]), np.ptp(df_in[\"LATITUDE\"]), np.ptp(df_in[\"LEV_M\"])/50))  # aspect ratio is 1:1:1 in data space\n",
    "plt.gca().invert_zaxis()\n",
    "plt.colorbar(sc_3d, location=\"bottom\", fraction=0.05, pad=0.01, label=\"Uncertainty [%]\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output_old/dbscan/uncertainty/uncertainty_withDrop_geospace.png\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "sc_umap = ax.scatter(df_in[\"e0\"], df_in[\"e1\"], df_in[\"e2\"], c=df_in[\"uncertainty\"], alpha=0.8, zorder=4, s=1)  # , s=s, alpha=1, zorder=4)\n",
    "plt.colorbar(sc_umap, location=\"bottom\", fraction=0.05, pad=0.05, label=\"Uncertainty [%]\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output_old/dbscan/uncertainty/uncertainty_withDrop_umapspace.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6185bf8-ae6e-4e16-bd48-15c12bc9ca42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5df93e6-5ddf-4082-9beb-bf6567623067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdce70a9-edf6-46c5-b0e6-1345e787bc5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f24180-1b76-44c4-8c5b-ca0b43d9259b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e63eec4-9586-48c1-9f99-1cdc42a9363c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2cc861-d45f-46c0-b775-b3c1f42ef58e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc3f75f-8a80-4b59-bf31-c7eac84c1dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
